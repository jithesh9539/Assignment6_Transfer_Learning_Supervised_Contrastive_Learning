{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment6_Transfer_Learning_Part1_Supervise_Contrastive_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSNdiBzNvU9zESjxs4zH9T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jithesh9539/Assignment6_Transfer_Learning_Supervised_Contrastive_Learning/blob/main/Assignment6_Transfer_Learning_Part1_Supervise_Contrastive_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Dependencies**"
      ],
      "metadata": {
        "id": "YYNS39NiS-am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons==0.8.3\n",
        "!pip install tensorflow==2.2.0-rc3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl6nYNqdTR0x",
        "outputId": "bfb661f2-25e3-4f6d-dc7e-0156e7e3ea94"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==0.8.3\n",
            "  Downloading tensorflow_addons-0.8.3-cp37-cp37m-manylinux2010_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons==0.8.3) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.8.3\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.2.0-rc3 (from versions: 1.13.1, 1.13.2, 1.14.0, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tensorflow==2.2.0-rc3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Dependencies**"
      ],
      "metadata": {
        "id": "PJrGaoyMWg_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "hSa7n_h6ewfR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**"
      ],
      "metadata": {
        "id": "mniGQHImWohO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Image Data**"
      ],
      "metadata": {
        "id": "NQbQpszWW7Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Load the train and test data splits\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Display shapes of train and test datasets\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxAEX7PwWgO4",
        "outputId": "5f55d61f-5323-42e4-bb7f-da04e47a33e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.02),\n",
        "        layers.RandomWidth(0.2),\n",
        "        layers.RandomHeight(0.2),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "dldKMaOFWrLk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the state of the normalization layer.\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ],
      "metadata": {
        "id": "5-yBYRD1XAo-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding the model**"
      ],
      "metadata": {
        "id": "_gaHb3xeXJGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_encoder():\n",
        "    resnet = keras.applications.ResNet50V2(\n",
        "        include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\"\n",
        "    )\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    augmented = data_augmentation(inputs)\n",
        "    outputs = resnet(augmented)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
        "    return model\n",
        "\n",
        "\n",
        "encoder = create_encoder()\n",
        "encoder.summary()\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 265\n",
        "hidden_units = 512\n",
        "projection_units = 128\n",
        "num_epochs = 2\n",
        "dropout_rate = 0.5\n",
        "temperature = 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBZpyQlXXDll",
        "outputId": "d8ed307a-5e04-4b2b-93ae-3eba4d5324d5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cifar10-encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 32, 32, 3)         7         \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,564,807\n",
            "Trainable params: 23,519,360\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Build the classification model\n",
        "\"\"\"The classification model adds a fully-connected layer on top of the encoder,\n",
        "plus a softmax layer with the target classes.\"\"\"\n",
        "\n",
        "\n",
        "def create_classifier(encoder, trainable=True):\n",
        "\n",
        "    for layer in encoder.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "kegKCTUZXNXj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the baseline classification model**"
      ],
      "metadata": {
        "id": "RrmF_eN_Xh9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = create_encoder()\n",
        "classifier = create_classifier(encoder)\n",
        "classifier.summary()\n",
        "\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8IleQ58Xb2y",
        "outputId": "6bb77ea4-399b-41dd-d687-a80f12426141"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cifar10-classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " cifar10-encoder (Functional  (None, 2048)             23564807  \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,619,025\n",
            "Trainable params: 24,573,578\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "189/189 [==============================] - 5026s 27s/step - loss: 1.9238 - sparse_categorical_accuracy: 0.2962\n",
            "Epoch 2/2\n",
            "189/189 [==============================] - 5183s 27s/step - loss: 1.5281 - sparse_categorical_accuracy: 0.4472\n",
            "313/313 [==============================] - 40s 125ms/step - loss: 1471.3503 - sparse_categorical_accuracy: 0.1018\n",
            "Test accuracy: 10.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Supervised Contrastive Learning Loss Function**"
      ],
      "metadata": {
        "id": "4gcVeSJJYCtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
        "    def __init__(self, temperature=1, name=None):\n",
        "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # Normalize feature vectors\n",
        "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "        # Compute logits\n",
        "        logits = tf.divide(\n",
        "            tf.matmul(\n",
        "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
        "            ),\n",
        "            self.temperature,\n",
        "        )\n",
        "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)"
      ],
      "metadata": {
        "id": "BxG-XPKFX_Js"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_projection_head(encoder):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
        "    model = keras.Model(\n",
        "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "uwYbe515YP3p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pretrain the encoder**"
      ],
      "metadata": {
        "id": "jMYLRgi7YTca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = create_encoder()\n",
        "\n",
        "encoder_with_projection_head = add_projection_head(encoder)\n",
        "encoder_with_projection_head.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss=SupervisedContrastiveLoss(temperature),\n",
        ")\n",
        "\n",
        "encoder_with_projection_head.summary()\n",
        "\n",
        "history = encoder_with_projection_head.fit(\n",
        "    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulRYtyySYTGu",
        "outputId": "11c313cd-50f8-4ca9-a9f1-ba3231c822e1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cifar-encoder_with_projection-head\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " cifar10-encoder (Functional  (None, 2048)             23564807  \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               262272    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,827,079\n",
            "Trainable params: 23,781,632\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "189/189 [==============================] - 5268s 28s/step - loss: 5.3573\n",
            "Epoch 2/2\n",
            "189/189 [==============================] - 5174s 27s/step - loss: 5.1455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train classifier with the encoder**"
      ],
      "metadata": {
        "id": "plH_I_h0YchB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = create_classifier(encoder, trainable=False)\n",
        "\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deFCJF2NYibl",
        "outputId": "ef64a710-b3f2-43c8-cbdc-15e73197775e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "189/189 [==============================] - 216s 1s/step - loss: 1.6266 - sparse_categorical_accuracy: 0.4260\n",
            "Epoch 2/2\n",
            "189/189 [==============================] - 204s 1s/step - loss: 1.4848 - sparse_categorical_accuracy: 0.4496\n",
            "313/313 [==============================] - 40s 124ms/step - loss: 1.4697 - sparse_categorical_accuracy: 0.4542\n",
            "Test accuracy: 45.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ajSq0931IhIg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}